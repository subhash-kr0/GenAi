{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2e6c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q langchain_core langchain_community langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "432594af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install SpeechRecognition pyttsx3\n",
    "# !pip install pyaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be15567",
   "metadata": {},
   "source": [
    "## Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6e54fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\123sa\\AppData\\Local\\Temp\\ipykernel_11672\\3129996719.py:50: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"history\", input_key=\"question\")\n",
      "C:\\Users\\123sa\\AppData\\Local\\Temp\\ipykernel_11672\\3129996719.py:53: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  qa_chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Initialize Groq LLM\n",
    "groq_api_key = \"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\"  # Replace with your actual API key\n",
    "llm = ChatGroq(\n",
    "    api_key=groq_api_key,\n",
    "    model=\"mixtral-8x7b-32768\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "# Custom Prompt\n",
    "custom_prompt_template_for_chatbot = \"\"\"\n",
    "You are a knowledgeable assistant specializing in Data Science and Artificial Intelligence (AI).\n",
    "\n",
    "Your primary objective is to assist students by providing clear, concise, and accurate answers to their questions specifically related to Data Science and AI. This includes, but is not limited to, the following topics:\n",
    "- Programming languages and tools: Python, SQL (MySQL, SQLite, MongoDB)\n",
    "- Data visualization tools: Power BI, Tableau\n",
    "- Statistical concepts and methodologies\n",
    "- Machine Learning (ML) techniques and frameworks\n",
    "- MLFlow for managing machine learning workflows\n",
    "- Containerization with Docker\n",
    "- Deep Learning concepts and frameworks\n",
    "- Natural Language Processing (NLP)\n",
    "- Generative AI technologies\n",
    "- Skills required for a career in Data Science and AI\n",
    "\n",
    "When responding, ensure that your answers are focused and straightforward, avoiding unnecessary details. If users ask complex questions, break down your responses into manageable parts and provide step-by-step explanations when needed.\n",
    "\n",
    "Always be polite and encouraging, ensuring that you provide accurate information at all times.\n",
    "\n",
    "Remember previous exchanges in the conversation to provide better context for your responses.\n",
    "\n",
    "If a question is asked that falls outside the realm of Data Science and AI or does not relate to the topics mentioned above, respond with a polite message indicating that the question is unrelated. For example: \"I'm sorry, but that topic is outside the scope of Data Science and AI. I'm unable to provide an answer.\"\n",
    "\n",
    "Question: {history} Current question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=custom_prompt_template_for_chatbot,\n",
    "    input_variables=[\"history\", \"question\"],\n",
    ")\n",
    "\n",
    "# Initialize memory\n",
    "memory = ConversationBufferMemory(memory_key=\"history\", input_key=\"question\")\n",
    "\n",
    "# Create chain with memory\n",
    "qa_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "\n",
    "# Function to Handle Q&A\n",
    "def handle_qna(user_input):\n",
    "    \"\"\"\n",
    "    Handles user queries for Q&A functionality.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = qa_chain.run(user_input)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred while processing your question: {e}\"\n",
    "\n",
    "# Integration into Chat Assistant\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(\"Q&A Module Test: Ask me anything related to Data Science and AI!\")\n",
    "#     while True:\n",
    "#         user_question = input(\"You: \")\n",
    "#         if user_question.lower() in [\"exit\", \"quit\"]:\n",
    "#             print(\"Goodbye!\")\n",
    "#             break\n",
    "#         print(f\"Assistant: {handle_qna(user_question)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc261f42",
   "metadata": {},
   "source": [
    "## Set remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "272638ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import threading\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Global dictionary to store active reminders\n",
    "reminders = []\n",
    "conversation_context = {}\n",
    "\n",
    "def normalize_time(user_input):\n",
    "    \"\"\"\n",
    "    Normalize unconventional time inputs into a valid 12-hour HH:MM AM/PM format.\n",
    "    For example:\n",
    "    - '914pm' -> '09:14 PM'\n",
    "    - '915pm' -> '09:15 PM'\n",
    "    - '9pm' -> '09:00 PM'\n",
    "    \"\"\"\n",
    "    # Extract numbers and AM/PM\n",
    "    match = re.match(r'(\\d{1,4})(AM|PM|am|pm)?', user_input, re.IGNORECASE)\n",
    "    if not match:\n",
    "        return None  # Invalid input\n",
    "    \n",
    "    raw_time = match.group(1)  # Extract the numeric part\n",
    "    period = match.group(2).upper() if match.group(2) else \"PM\"  # Default to PM if not provided\n",
    "\n",
    "    # Handle different lengths of the raw_time\n",
    "    if len(raw_time) == 1 or len(raw_time) == 2:  # e.g., '9' or '12'\n",
    "        hour = int(raw_time)\n",
    "        minute = 0\n",
    "    elif len(raw_time) == 3:  # e.g., '914' -> hour: 9, minute: 14\n",
    "        hour = int(raw_time[0])\n",
    "        minute = int(raw_time[1:])\n",
    "    elif len(raw_time) == 4:  # e.g., '0915' or '915' -> hour: 9, minute: 15\n",
    "        hour = int(raw_time[:2])\n",
    "        minute = int(raw_time[2:])\n",
    "    else:\n",
    "        return None  # Invalid input length\n",
    "\n",
    "    # Adjust hour and minute for valid time ranges\n",
    "    while minute >= 60:\n",
    "        hour += 1\n",
    "        minute -= 60\n",
    "\n",
    "    # Convert to 12-hour format\n",
    "    if hour > 12:\n",
    "        hour %= 12\n",
    "    if hour == 0:\n",
    "        hour = 12\n",
    "\n",
    "    # Format into HH:MM AM/PM\n",
    "    try:\n",
    "        normalized_time = datetime.strptime(f\"{hour}:{minute:02d} {period}\", \"%I:%M %p\")\n",
    "        return normalized_time.strftime(\"%I:%M %p\")\n",
    "    except ValueError:\n",
    "        return None  # Invalid input after adjustments\n",
    "\n",
    "# Reminder Handler\n",
    "def handle_reminder(user_input):\n",
    "    \"\"\"\n",
    "    Handles setting reminders interactively with the user.\n",
    "    \"\"\"\n",
    "    global conversation_context\n",
    "\n",
    "    # If there's a pending_action in conversation_context, continue that flow\n",
    "    if \"pending_action\" in conversation_context:\n",
    "        action = conversation_context.pop(\"pending_action\")\n",
    "        if action == \"set_reminder_time\":\n",
    "            # Normalize time input\n",
    "            normalized_time = normalize_time(user_input)\n",
    "            if not normalized_time:\n",
    "                return \"Invalid time format. Please provide the time in HH:MM AM/PM format (e.g., 02:30 PM).\"\n",
    "            conversation_context[\"reminder_time\"] = normalized_time\n",
    "            conversation_context[\"pending_action\"] = \"set_reminder_message\"\n",
    "            return \"What should I remind you about?\"\n",
    "        elif action == \"set_reminder_message\":\n",
    "            # Now we have time and message, we can set the reminder\n",
    "            reminder_time = conversation_context.pop(\"reminder_time\")\n",
    "            reminder_message = user_input\n",
    "            set_reminder(reminder_time, reminder_message)\n",
    "            return f\"Reminder set for {reminder_time} with message: '{reminder_message}'\"\n",
    "    else:\n",
    "        # Start the reminder setting process\n",
    "        conversation_context[\"pending_action\"] = \"set_reminder_time\"\n",
    "        return \"What time should I set the reminder for? (e.g., 02:30 PM)\"\n",
    "\n",
    "def set_reminder(reminder_time, message):\n",
    "    \"\"\"\n",
    "    Create a background thread that triggers at the exact reminder_time (12-hour format).\n",
    "    \"\"\"\n",
    "    def reminder_thread():\n",
    "        while True:\n",
    "            current_time = datetime.now().strftime(\"%I:%M %p\")  # 12-hour format\n",
    "            if current_time == reminder_time:\n",
    "                print(f\"\\nReminder: {message}\")\n",
    "                break\n",
    "            time.sleep(1)\n",
    "\n",
    "    reminders.append({\"time\": reminder_time, \"message\": message})\n",
    "    threading.Thread(target=reminder_thread, daemon=True).start()\n",
    "\n",
    "# Test Reminder Functionality\n",
    "# if __name__ == \"__main__\":\n",
    "#     conversation_context = {}  # Initialize global conversation context\n",
    "#     print(\"Welcome to the Reminder Module!\")\n",
    "#     print(\"You can interactively set reminders.\")\n",
    "\n",
    "#     while True:\n",
    "#         user_input = input(\"You: \").strip()\n",
    "#         if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "#             print(\"Goodbye!\")\n",
    "#             break\n",
    "#         response = handle_reminder(user_input)\n",
    "#         print(f\"Assistant: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc140e6",
   "metadata": {},
   "source": [
    "## Weather Fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f22cc63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather(location):\n",
    "    \"\"\"\n",
    "    Fetch the weather details for a given location using Open-Meteo.\n",
    "    \"\"\"\n",
    "    geocode_url = f\"https://geocoding-api.open-meteo.com/v1/search?name={location}\"\n",
    "\n",
    "    try:\n",
    "        # Fetch latitude and longitude\n",
    "        geocode_response = requests.get(geocode_url)\n",
    "        geocode_response.raise_for_status()\n",
    "        geocode_data = geocode_response.json()\n",
    "\n",
    "        if \"results\" not in geocode_data or len(geocode_data[\"results\"]) == 0:\n",
    "            return f\"Sorry, I couldn't find weather details for '{location}'. Please try another location.\"\n",
    "\n",
    "        latitude = geocode_data[\"results\"][0][\"latitude\"]\n",
    "        longitude = geocode_data[\"results\"][0][\"longitude\"]\n",
    "        location_name = geocode_data[\"results\"][0][\"name\"]\n",
    "\n",
    "        # Fetch weather details\n",
    "        weather_url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current_weather=true\"\n",
    "        weather_response = requests.get(weather_url)\n",
    "        weather_response.raise_for_status()\n",
    "        weather_data = weather_response.json()\n",
    "\n",
    "        if \"current_weather\" in weather_data:\n",
    "            current_weather = weather_data[\"current_weather\"]\n",
    "            temperature = current_weather[\"temperature\"]\n",
    "            windspeed = current_weather[\"windspeed\"]\n",
    "            weather_code = current_weather.get(\"weathercode\", -1)\n",
    "\n",
    "            weather_conditions = {\n",
    "                0: \"Clear sky\",\n",
    "                1: \"Mainly clear\",\n",
    "                2: \"Partly cloudy\",\n",
    "                3: \"Overcast\",\n",
    "                45: \"Foggy\",\n",
    "                48: \"Depositing rime fog\",\n",
    "                51: \"Light drizzle\",\n",
    "                53: \"Moderate drizzle\",\n",
    "                55: \"Dense drizzle\",\n",
    "                61: \"Slight rain\",\n",
    "                63: \"Moderate rain\",\n",
    "                65: \"Heavy rain\",\n",
    "                71: \"Slight snow\",\n",
    "                73: \"Moderate snow\",\n",
    "                75: \"Heavy snow\",\n",
    "                80: \"Rain showers\",\n",
    "                81: \"Moderate rain showers\",\n",
    "                82: \"Heavy rain showers\",\n",
    "                95: \"Thunderstorm\",\n",
    "                96: \"Thunderstorm with hail\",\n",
    "            }\n",
    "            weather_description = weather_conditions.get(weather_code, \"Unknown conditions\")\n",
    "\n",
    "            temperature_description = (\n",
    "                \"hot\" if temperature > 30 else \"cold\" if temperature < 15 else \"moderate\"\n",
    "            )\n",
    "\n",
    "            return (f\"The current weather in {location_name} is {weather_description} with a temperature of \"\n",
    "                    f\"{temperature}°C ({temperature_description}) and a windspeed of {windspeed} km/h.\")\n",
    "        else:\n",
    "            return \"Sorry, I couldn't fetch the weather details at this time.\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"An error occurred while fetching weather data: {e}\"\n",
    "\n",
    "def handle_weather(user_input):\n",
    "    \"\"\"\n",
    "    Handles weather-related queries interactively with the user.\n",
    "    \"\"\"\n",
    "    global current_functionality, conversation_context\n",
    "\n",
    "    # Directly fetch weather if functionality is already set to 'weather'\n",
    "    if current_functionality == \"weather\":\n",
    "        if user_input.lower() == \"exit\":\n",
    "            current_functionality = None\n",
    "            return \"Exited the weather functionality. How can I assist you next?\"\n",
    "        return fetch_weather(user_input.strip())\n",
    "\n",
    "    # Detect if location is already mentioned in the first input\n",
    "    if user_input.lower() in [\"weather\", \"weather update\", \"what's the weather outside\"]:\n",
    "        current_functionality = \"weather\"\n",
    "        return \"For which location would you like to get the weather?\"\n",
    "\n",
    "    # Assume the user input is a location on the first call\n",
    "    current_functionality = \"weather\"\n",
    "    return fetch_weather(user_input.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039eef35",
   "metadata": {},
   "source": [
    "## Play Music from youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad15af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agent for music\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "music_player = None  # Global music player\n",
    "\n",
    "# Initialize LLM for Music Query Processing\n",
    "llm_music = ChatGroq(\n",
    "    api_key=\"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\",\n",
    "    model=\"mixtral-8x7b-32768\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Few-shot examples for music queries\n",
    "music_few_shot_examples = [\n",
    "    {\"input\": \"Play the latest song by Taylor Swift.\", \"query\": \"latest song by Taylor Swift\"},\n",
    "    {\"input\": \"I want to listen to some relaxing piano music.\", \"query\": \"relaxing piano music\"},\n",
    "    {\"input\": \"Play Pushpa 2 title song.\", \"query\": \"Pushpa 2 title song\"},\n",
    "    {\"input\": \"Find and play some jazz music.\", \"query\": \"jazz music\"},\n",
    "    {\"input\": \"Despacito song\", \"query\": \"Despacito song\"},\n",
    "    {\"input\": \"I want the title song from the movie Pushpa.\", \"query\": \"title song from the movie Pushpa\"},\n",
    "    {\"input\": \"Play the Devara Telugu movie title song.\", \"query\": \"Devara Telugu movie title song\"},\n",
    "    {\"input\": \"Play something classical.\", \"query\": \"classical music\"},\n",
    "    {\"input\": \"Can you find a remix of Shape of You?\", \"query\": \"Shape of You remix\"},\n",
    "    {\"input\": \"Play Arijit Singh's latest hit.\", \"query\": \"Arijit Singh latest hit song\"},\n",
    "    {\"input\": \"Find and play a calming meditation track.\", \"query\": \"calming meditation track\"},\n",
    "    {\"input\": \"I want to hear Bollywood romantic songs.\", \"query\": \"Bollywood romantic songs\"},\n",
    "    {\"input\": \"Play a workout playlist.\", \"query\": \"workout playlist\"},\n",
    "    {\"input\": \"Do you have any rock music?\", \"query\": \"rock music\"},\n",
    "    {\"input\": \"Find a Telugu devotional song for me.\", \"query\": \"Telugu devotional song\"},\n",
    "    {\"input\": \"Play Ed Sheeran's Perfect.\", \"query\": \"Ed Sheeran Perfect\"},\n",
    "    {\"input\": \"Play the background score of Interstellar.\", \"query\": \"Interstellar background score\"},\n",
    "    {\"input\": \"Can you play 'Kala Chashma'?\", \"query\": \"Kala Chashma song\"},\n",
    "    {\"input\": \"I want to listen to a live version of Rolling in the Deep.\", \"query\": \"live version of Rolling in the Deep\"},\n",
    "    {\"input\": \"Find a trending pop song.\", \"query\": \"trending pop song\"},\n",
    "    {\"input\": \"Play some 90s hits.\", \"query\": \"90s hits\"},\n",
    "    {\"input\": \"Find an acoustic version of Hotel California.\", \"query\": \"acoustic version of Hotel California\"},\n",
    "    {\"input\": \"Play a party anthem.\", \"query\": \"party anthem\"},\n",
    "    {\"input\": \"Play something by Imagine Dragons.\", \"query\": \"Imagine Dragons songs\"},\n",
    "    {\"input\": \"I want to listen to Lofi beats.\", \"query\": \"Lofi beats\"},\n",
    "    {\"input\": \"Can you play the theme song from Harry Potter?\", \"query\": \"Harry Potter theme song\"},\n",
    "    {\"input\": \"Play a motivational song.\", \"query\": \"motivational song\"},\n",
    "    {\"input\": \"Find a Tamil melody.\", \"query\": \"Tamil melody\"},\n",
    "    {\"input\": \"Play the OST from Game of Thrones.\", \"query\": \"Game of Thrones OST\"},\n",
    "    {\"input\": \"Can you play a recent K-pop hit?\", \"query\": \"recent K-pop hit\"},\n",
    "    {\"input\": \"Play the soundtrack of Titanic.\", \"query\": \"Titanic soundtrack\"}\n",
    "]\n",
    "\n",
    "\n",
    "def refine_music_query(user_input):\n",
    "    \"\"\"\n",
    "    Use LLM to extract or infer the music query from user input with enhanced accuracy.\n",
    "    \"\"\"\n",
    "    few_shot_text = \"\\n\".join([f\"Input: {ex['input']} Query: {ex['query']}\" for ex in music_few_shot_examples])\n",
    "    prompt = f\"\"\"\n",
    "        You are a music query extraction assistant. Your task is to strictly extract the specific song name and language (if mentioned) \n",
    "        from the user's input. Follow these rules:\n",
    "\n",
    "        1. Output only the song name or genre and the language (if specified).\n",
    "        2. Do not include any additional interpretation, explanation, or context.\n",
    "        3. If the input is unclear or ambiguous, return only the most relevant key terms directly related to the song or genre or print the user input directly if it is not clear.\n",
    "\n",
    "        Here are examples:\n",
    "\n",
    "        {few_shot_text}\n",
    "\n",
    "        Input: {user_input}\n",
    "        Query:\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a music query refinement assistant, specializing in accurate song identification.\"),\n",
    "        HumanMessage(content=prompt)\n",
    "    ]\n",
    "    response = llm_music.invoke(messages)\n",
    "    refined_query = response.content.strip()\n",
    "    print(f\"[DEBUG] Refined Query: {refined_query}\")\n",
    "    return refined_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5d47378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "import vlc\n",
    "\n",
    "music_player = None  # Global music player\n",
    "\n",
    "def fetch_and_play_music(query):\n",
    "    \"\"\"\n",
    "    Search and play music from YouTube based on the refined query.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ydl_opts = {\n",
    "            'format': 'bestaudio/best',\n",
    "            'noplaylist': True,\n",
    "            'quiet': True,\n",
    "        }\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            results = ydl.extract_info(f\"ytsearch:{query}\", download=False)\n",
    "            if not results.get('entries'):\n",
    "                return None, \"No results found for your query. Please try a different song or check the title.\"\n",
    "            result = results['entries'][0]  # Take the first result\n",
    "            video_title = result['title']\n",
    "            video_url = result['url']\n",
    "\n",
    "            print(f\"Now playing: {video_title}\")\n",
    "\n",
    "            player = vlc.MediaPlayer(video_url)\n",
    "            player.play()\n",
    "\n",
    "            return player, f\"Playing: {video_title}. Type 'stop', 'exit', or 'quit' to stop the music.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return None, \"Sorry, I couldn't play the song due to a technical issue.\"\n",
    "\n",
    "\n",
    "def handle_play_music(user_input):\n",
    "    \"\"\"\n",
    "    Handles user requests to play music or stop it.\n",
    "    \"\"\"\n",
    "    global music_player\n",
    "\n",
    "    # Stop the current song\n",
    "    if user_input.lower().strip() in [\"stop\", \"exit\", \"quit\"]:\n",
    "        if music_player:\n",
    "            music_player.stop()\n",
    "            music_player = None\n",
    "            return \"Music stopped.\"\n",
    "        else:\n",
    "            return \"No music is currently playing.\"\n",
    "\n",
    "    # Refine the query\n",
    "    refined_query = refine_music_query(user_input)\n",
    "    if not refined_query:\n",
    "        return \"I couldn't understand the song you want to play. Could you try rephrasing?\"\n",
    "\n",
    "    # Stop any currently playing music before starting a new one\n",
    "    if music_player:\n",
    "        music_player.stop()\n",
    "        music_player = None\n",
    "\n",
    "    player, response = fetch_and_play_music(refined_query)\n",
    "    if player:  # If successful\n",
    "        music_player = player\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de40b09",
   "metadata": {},
   "source": [
    "## Main code - Chat Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bee5d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# import threading\n",
    "# import requests\n",
    "# import yt_dlp\n",
    "# import vlc\n",
    "# import random\n",
    "# import re\n",
    "# import json\n",
    "# from langchain_groq import ChatGroq\n",
    "# from langchain.schema import SystemMessage, HumanMessage\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# # ------------------ Global State ------------------\n",
    "# current_functionality = None\n",
    "# conversation_context = {}\n",
    "# music_player = None\n",
    "\n",
    "\n",
    "# # ------------------ Intent Detection Setup ------------------\n",
    "# llm_intent = ChatGroq(\n",
    "#     api_key=\"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\",\n",
    "#     model=\"mixtral-8x7b-32768\",\n",
    "#     temperature=0.7\n",
    "# )\n",
    "\n",
    "# few_shot_examples = [\n",
    "#     {\"input\": \"Can you explain what AI is?\", \"intent\": \"qna\"},\n",
    "#     {\"input\": \"Remind me to call John at 3 PM.\", \"intent\": \"reminder\"},\n",
    "#     {\"input\": \"What's the weather in Paris?\", \"intent\": \"weather\"},\n",
    "#     {\"input\": \"Play a song from YouTube\", \"intent\": \"music\"},\n",
    "# ]\n",
    "\n",
    "# def detect_intent(user_input):\n",
    "#     \"\"\"\n",
    "#     Use LLM to detect the intent of the user's query.\n",
    "#     \"\"\"\n",
    "#     few_shot_text = \"\\n\".join([f\"Input: {ex['input']} Intent: {ex['intent']}\" for ex in few_shot_examples])\n",
    "#     prompt = f\"\"\"\n",
    "#     Classify the user's query into one of these intents:\n",
    "#     - qna\n",
    "#     - reminder\n",
    "#     - weather\n",
    "#     - music\n",
    "\n",
    "#     Examples:\n",
    "#     {few_shot_text}\n",
    "\n",
    "#     Input: {user_input}\n",
    "#     Intent:\n",
    "#     \"\"\"\n",
    "#     messages = [\n",
    "#         SystemMessage(content=\"You are an intent detection assistant.\"),\n",
    "#         HumanMessage(content=prompt)\n",
    "#     ]\n",
    "#     response = llm_intent.invoke(messages)\n",
    "#     intent_detected = response.content.strip().lower()\n",
    "#     print(f\"[DEBUG] Detected Intent: {intent_detected}\")\n",
    "#     return intent_detected\n",
    "\n",
    "# # ------------------ Main Chat Assistant ------------------\n",
    "# def process_user_input(user_input):\n",
    "#     \"\"\"\n",
    "#     Route the user input to the appropriate functionality based on detected intent.\n",
    "#     \"\"\"\n",
    "#     global current_functionality, conversation_context\n",
    "#     global music_player\n",
    "\n",
    "#     # If inside a functionality, bypass intent detection\n",
    "#     if current_functionality:\n",
    "#         print(f\"[DEBUG] Continuing in {current_functionality} functionality.\")\n",
    "#         if user_input.lower() == \"exit\":\n",
    "#             if current_functionality == \"music\" and music_player:\n",
    "#                 music_player.stop()\n",
    "#                 music_player = None\n",
    "#             current_functionality = None\n",
    "#             conversation_context.clear()\n",
    "#             return \"Exited the current functionality. How can I assist you next?\"\n",
    "#         # Process input in the current functionality\n",
    "#         if current_functionality == \"qna\":\n",
    "#             return handle_qna(user_input)\n",
    "#         elif current_functionality == \"reminder\":\n",
    "#             return handle_reminder(user_input)\n",
    "#         elif current_functionality == \"weather\":\n",
    "#             return handle_weather(user_input)\n",
    "#         elif current_functionality == \"music\":\n",
    "#             return handle_play_music(user_input)\n",
    "\n",
    "\n",
    "\n",
    "#     # Detect intent for new input\n",
    "#     intent = detect_intent(user_input)\n",
    "#     print(f\"[DEBUG] Detected Intent: {intent}\")  # Debugging intent detection\n",
    "\n",
    "#     # Update current functionality and initiate it\n",
    "#     if intent in [\"qna\", \"reminder\", \"weather\", \"music\", \"quiz\"]:\n",
    "#         current_functionality = intent\n",
    "#         return process_user_input(user_input)\n",
    "#     elif intent == \"qna\" or intent not in [\"reminder\", \"weather\", \"music\"]:\n",
    "#         # Default to Q&A handler if the intent is Q&A or unknown\n",
    "#         current_functionality = \"qna\"\n",
    "#         return handle_qna(user_input)\n",
    "#     else:\n",
    "#         return \"I'm sorry, I couldn't understand that. Could you try rephrasing your request?\"\n",
    "\n",
    "# def chat_assistant():\n",
    "#     \"\"\"\n",
    "#     Main loop for the chat assistant.\n",
    "#     \"\"\"\n",
    "#     print(\"Welcome to your Chat Assistant!\")\n",
    "#     print(\"You can ask me to set reminders, fetch weather, play music, manage to-dos, or play a quiz.\")\n",
    "#     print(\"Type 'exit' to leave a functionality or 'quit' to end the chat.\\n\")\n",
    "\n",
    "#     while True:\n",
    "#         user_input = input(\"You: \").strip()\n",
    "#         if user_input.lower() in [\"quit\"]:\n",
    "#             print(\"Assistant: Goodbye! Have a great day!\")\n",
    "#             break\n",
    "\n",
    "#         # Process the user input and return the response\n",
    "#         response = process_user_input(user_input)\n",
    "#         print(f\"Assistant: {response}\")\n",
    "\n",
    "# # Run the assistant\n",
    "# if __name__ == \"__main__\":\n",
    "#     chat_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3f981c",
   "metadata": {},
   "source": [
    "## Main Code - Voice Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "166f7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from datetime import datetime\n",
    "import threading\n",
    "import requests\n",
    "import yt_dlp\n",
    "import vlc\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "########################################\n",
    "# 2) Your unchanged global states & variables\n",
    "########################################\n",
    "current_functionality = None\n",
    "conversation_context = {}\n",
    "music_player = None\n",
    "\n",
    "########################################\n",
    "# 3) TTS (Text-to-Speech) Setup\n",
    "########################################\n",
    "tts_engine = pyttsx3.init()\n",
    "# Adjust speaking rate (200 is fairly normal speed)\n",
    "tts_engine.setProperty('rate', 200)\n",
    "\n",
    "def speak(text: str):\n",
    "    \"\"\"\n",
    "    Convert text to speech and also show it (like print).\n",
    "    \"\"\"\n",
    "    print(f\"Assistant: {text}\")\n",
    "    tts_engine.say(text)\n",
    "    tts_engine.runAndWait()\n",
    "\n",
    "########################################\n",
    "# 4) STT (Speech-to-Text) Setup\n",
    "########################################\n",
    "recognizer = sr.Recognizer()\n",
    "microphone = sr.Microphone()\n",
    "\n",
    "def listen_for_command() -> str:\n",
    "    \"\"\"\n",
    "    Listen via microphone and return recognized text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with microphone as source:\n",
    "            # Optional: adjust for ambient noise\n",
    "            recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "            speak(\"Listening...\")\n",
    "            audio = recognizer.listen(source)\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(f\"You: {text}\")\n",
    "        return text.strip()\n",
    "    except sr.UnknownValueError:\n",
    "        return \"\"\n",
    "    except sr.RequestError:\n",
    "        return \"\"\n",
    "\n",
    "########################################\n",
    "# 5) Your unchanged code from the question\n",
    "#    (We just copy/paste your logic exactly,\n",
    "#    so that we do not alter it.)\n",
    "########################################\n",
    "\n",
    "# -- LLM for intent detection (unchanged) --\n",
    "llm_intent = ChatGroq(\n",
    "    api_key=\"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\",\n",
    "    model=\"mixtral-8x7b-32768\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "few_shot_examples = [\n",
    "    {\"input\": \"Can you explain what AI is?\", \"intent\": \"qna\"},\n",
    "    {\"input\": \"Remind me to call John at 3 PM.\", \"intent\": \"reminder\"},\n",
    "    {\"input\": \"What's the weather in Paris?\", \"intent\": \"weather\"},\n",
    "    {\"input\": \"Play a song from YouTube\", \"intent\": \"music\"},\n",
    "]\n",
    "\n",
    "def detect_intent(user_input):\n",
    "    \"\"\"\n",
    "    Use LLM to detect the intent of the user's query.\n",
    "    \"\"\"\n",
    "    few_shot_text = \"\\n\".join([f\"Input: {ex['input']} Intent: {ex['intent']}\" for ex in few_shot_examples])\n",
    "    prompt = f\"\"\"\n",
    "    Classify the user's query into one of these intents:\n",
    "    - qna\n",
    "    - reminder\n",
    "    - weather\n",
    "    - music\n",
    "\n",
    "    Examples:\n",
    "    {few_shot_text}\n",
    "\n",
    "    Input: {user_input}\n",
    "    Intent:\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are an intent detection assistant.\"),\n",
    "        HumanMessage(content=prompt)\n",
    "    ]\n",
    "    response = llm_intent.invoke(messages)\n",
    "    intent_detected = response.content.strip().lower()\n",
    "    print(f\"[DEBUG] Detected Intent: {intent_detected}\")\n",
    "    return intent_detected\n",
    "\n",
    "# -------------\n",
    "# Next, your process_user_input(...) from the question,\n",
    "# exactly as written, with your same logic\n",
    "# (i.e. skipping user_input if inside a functionality, etc.)\n",
    "# -------------\n",
    "def process_user_input(user_input):\n",
    "    \"\"\"\n",
    "    Route the user input to the appropriate functionality \n",
    "    based on detected intent (unchanged from your question).\n",
    "    \"\"\"\n",
    "    global current_functionality, conversation_context, music_player\n",
    "\n",
    "    # If inside a functionality, bypass intent detection\n",
    "    if current_functionality:\n",
    "        print(f\"[DEBUG] Continuing in {current_functionality} functionality.\")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            if current_functionality == \"music\" and music_player:\n",
    "                music_player.stop()\n",
    "                music_player = None\n",
    "            current_functionality = None\n",
    "            conversation_context.clear()\n",
    "            return \"Exited the current functionality. How can I assist you next?\"\n",
    "\n",
    "        # If you have Q&A, reminder, weather, etc. placeholders:\n",
    "        if current_functionality == \"qna\":\n",
    "            return handle_qna(user_input)\n",
    "        elif current_functionality == \"reminder\":\n",
    "            return handle_reminder(user_input)\n",
    "        elif current_functionality == \"weather\":\n",
    "            return handle_weather(user_input)\n",
    "        elif current_functionality == \"music\":\n",
    "            return handle_play_music(user_input)\n",
    "\n",
    "\n",
    "    # If not in any functionality, detect the intent\n",
    "    intent = detect_intent(user_input)\n",
    "    print(f\"[DEBUG] Detected Intent: {intent}\")\n",
    "\n",
    "    # Switch functionalities or default to qna\n",
    "    if intent in [\"qna\", \"reminder\", \"weather\", \"music\", \"quiz\"]:\n",
    "        current_functionality = intent\n",
    "        return process_user_input(user_input)\n",
    "    elif intent == \"qna\" or intent not in [\"reminder\", \"weather\", \"music\"]:\n",
    "        current_functionality = \"qna\"\n",
    "        return handle_qna(user_input)\n",
    "    else:\n",
    "        return \"I'm sorry, I couldn't understand that. Could you try rephrasing your request?\"\n",
    "\n",
    "########################################\n",
    "# 6) ADD YOUR HANDLERS EXACTLY\n",
    "#    (Placeholder stubs shown here)\n",
    "########################################\n",
    "# def handle_qna(user_input):\n",
    "#     # Example stub\n",
    "#     return \"Q&A placeholder.\"\n",
    "\n",
    "# def handle_reminder(user_input):\n",
    "#     # Example stub\n",
    "#     return \"Reminder placeholder.\"\n",
    "\n",
    "# def handle_weather(user_input):\n",
    "#     # Example stub\n",
    "#     return \"Weather placeholder.\"\n",
    "\n",
    "# def handle_play_music(user_input):\n",
    "#     # Example stub\n",
    "#     return \"Music placeholder.\"\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "# 7) The Voice Assistant Main Loop\n",
    "########################################\n",
    "def voice_assistant():\n",
    "    \"\"\"\n",
    "    Main voice-based loop that does:\n",
    "    - TTS for greeting\n",
    "    - STT to get user input\n",
    "    - Pass user input to your existing process_user_input\n",
    "    - TTS the response\n",
    "    - Repeat until user says \"quit\"\n",
    "    \"\"\"\n",
    "    speak(\"Hello! Welcome to your Voice Assistant.\")\n",
    "    speak(\"You can ask me to set reminders, fetch weather, play music, manage to-dos, or ask general questions.\")\n",
    "    speak(\"Say 'quit' at any time to end our session.\")\n",
    "\n",
    "    while True:\n",
    "        # Listen for user speech\n",
    "        user_input = listen_for_command()\n",
    "        if not user_input:\n",
    "            speak(\"Sorry, I didn't catch that. Please try again.\")\n",
    "            continue\n",
    "\n",
    "        # If user says 'quit'\n",
    "        if user_input.lower() == \"quit\":\n",
    "            speak(\"Goodbye! Have a great day!\")\n",
    "            break\n",
    "\n",
    "        # Otherwise, process the input\n",
    "        response = process_user_input(user_input)\n",
    "        # Speak the result\n",
    "        speak(response)\n",
    "\n",
    "\n",
    "########################################\n",
    "# 8) Entry point\n",
    "########################################\n",
    "if __name__ == \"__main__\":\n",
    "    # Just run voice assistant (no text-based chat)\n",
    "    voice_assistant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d1ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b87674c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
