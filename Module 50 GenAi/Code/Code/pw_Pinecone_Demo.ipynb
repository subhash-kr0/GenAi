{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Pinecone: https://www.pinecone.io/"
      ],
      "metadata": {
        "id": "fZ4b4j8LKS_Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If7W46lCJ6h6",
        "outputId": "904cc578-1799-4c86-cc46-4319652c8f68",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.9)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.9)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.21)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.28.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Collecting pinecone-client==2.2.4\n",
            "  Downloading pinecone_client-2.2.4-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (2.32.3)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (6.0.2)\n",
            "Collecting loguru>=0.5.0 (from pinecone-client==2.2.4)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (4.12.2)\n",
            "Collecting dnspython>=2.0.0 (from pinecone-client==2.2.4)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (4.66.6)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==2.2.4) (1.26.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone-client==2.2.4) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client==2.2.4) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client==2.2.4) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client==2.2.4) (2024.8.30)\n",
            "Downloading pinecone_client-2.2.4-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.4/179.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: loguru, dnspython, pinecone-client\n",
            "Successfully installed dnspython-2.7.0 loguru-0.7.3 pinecone-client-2.2.4\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install pinecone-client==2.2.4\n",
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers==2.2.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2UqWdrIL98m",
        "outputId": "d37a8af5-0099-4160-b484-c0c4f5f7da50",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers==2.2.2\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (4.46.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.13.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (3.9.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.26.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.2.2) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers==2.2.2) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.8.30)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125924 sha256=7fcaf067c606f8488eed1ebfab288eff5e2855b38014fd5c5e6a487538bdf5ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentence-transformers\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 3.2.1\n",
            "    Uninstalling sentence-transformers-3.2.1:\n",
            "      Successfully uninstalled sentence-transformers-3.2.1\n",
            "Successfully installed sentence-transformers-2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir pdfs"
      ],
      "metadata": {
        "id": "mdOSMa98MNGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract the Text from the PDF's"
      ],
      "metadata": {
        "id": "8PlnBWxDNN7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv_IMZgpTDyH",
        "outputId": "20a7d0ea-29f3-495d-f68b-3e290f3be7d9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.9)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.11 (from langchain-community)\n",
            "  Downloading langchain-0.3.11-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.24 (from langchain-community)\n",
            "  Downloading langchain_core-0.3.24-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.11->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.11->langchain-community) (2.10.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.28.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community) (2.27.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.2.2)\n",
            "Downloading langchain_community-0.3.11-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.11-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.24-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.21\n",
            "    Uninstalling langchain-core-0.3.21:\n",
            "      Successfully uninstalled langchain-core-0.3.21\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.9\n",
            "    Uninstalling langchain-0.3.9:\n",
            "      Successfully uninstalled langchain-0.3.9\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.11 langchain-community-0.3.11 langchain-core-0.3.24 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFDirectoryLoader"
      ],
      "metadata": {
        "id": "KKF5G9mLNSe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFDirectoryLoader(\"pdfs\")\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "wptoFDrKMcD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysXxXBW6NTy0",
        "outputId": "8e6e8220-95e3-4345-de27-d4ff85c5a06c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'pdfs/what_is_data_science.pdf', 'page': 0}, page_content='5What is data science?\\n1.1 What is data science?\\nData science is the practice of using data to try to understand and solve real-world prob-\\nlems. This concept isn’t exac tly new; people have been analyzing sales figures and\\ntrends since the invention of the zero. In the past decade, however, we have gained\\naccess to exponentially more data than ex isted before. The advent of computers has\\nassisted in the generation of all that data, but computing is also our only way to pro-\\ncess the mounds of information. With computer code, a data scientist can transform\\nor aggregate data, run statistical analyses, or train machine learning models. The out-\\nput of this code may be a report or dashboard for human consumption, or it could be\\na machine learning model that will be deployed to run continuously.\\n If a retail company is having trouble deciding where to put a new store, for exam-\\nple, it may call in a data scientist to do an analysis. The data scientist could look at the\\nhistorical data of locations where online orders are shipped to understand where cus-\\ntomer demand is. They may also combine that customer location data with demo-\\ngraphic and income information for those loca lities from census records. With these\\ndatasets, they could find the optimal plac e for the new store and create a Microsoft\\nPowerPoint presentation to  p r e s e n t  t h e i r  r e c o m m e n d a t i o n  t o  t h e  c o m p a n y ’ s  v i c e\\npresident of retail operations.\\n In another situation, that same retail company may want to increase online order\\nsizes by recommending items to customers while they shop. A data scientist could load\\nthe historical web order data and create a machine learning model that, given a set of\\nitems currently in the cart, predicts the best item to recommend to the shopper. After\\ncreating that model, the data scientist would work with the company’s engineering\\nteam so that every time a customer is shopping, the new machine learning model\\nserves up the recommended items.\\n When many people start looking into data science, one challenge they face is\\nbeing overwhelmed by the amount of things they need to learn, such as coding (but\\nwhich language?), statistics (but which methods are most important in practice, and\\nwhich are largely academic?), machine learning (but how is machine learning differ-\\nent from statistics or AI?), and the domain knowledge of whatever industry they want\\nto work in (but what if you don\\'t know where you want to work?). In addition, they\\nneed to learn business skills su ch as effec ti v ely commu nicating results to audiences\\nranging from other data scientists to the CEO. This anxiety can be exacerbated by job\\npostings that ask for a PhD, multiple years of data science experience, and expertise in\\na laundry list of statistical and programm ing methods. How can you possibly learn all\\nthese skills? Which ones should you start with? What are the basics?\\n If you’ve looked into the different areas of data science, you may be familiar with\\nDrew Conway’s popular data science Venn diagram. In Conway’s opinion (at the time of\\nthe diagram’s creation), data science fell into t he  i n t e r s e c t i o n o f  m a t h a n d  s t a t i s t i c a l\\nLicensed to Adriana Picoral <adrianaps@email.arizona.edu>\\nExcerpt from \"Build a Career in Data Science\" by Emily Robinson and Jacqueline Nolis (2020) ISBN: 9781617296246'),\n",
              " Document(metadata={'source': 'pdfs/what_is_data_science.pdf', 'page': 1}, page_content='6 CHAPTER  1 What is data science?\\nknowledge, expertise in a do main, and hacking skills (tha t is, coding). This image is\\noften used as the cornerstone of defining wh at a data scientist is. From our perspective,\\nthe components of data science are slightly different from what he proposed (figure 1.1).\\nWe’ve changed Conway’s original Venn diagram to a triangle because it’s not that you\\neither have a skill or you don’t; it’s that  you may possess it to a different extent from\\nothers in the field. Although it’s true that  all three skills are fundamental and that you\\nneed to have each to a degree, you don’t need  to be an expert in all of them. We put\\nwithin the triangle different types of data science specialties. These specialties don’t\\nalways map one-to-one with job titles, an d even when they do, different companies\\nsometimes call them different things.\\n So what does each of these components mean?\\n1.1.1 Mathematics/statistics\\nAt the basic level, mathematics and statistics  knowledge is data literacy. We break down\\nthat literacy into three levels of knowledge:\\n\\x83 That techniques exist —If you don’t know that something is possible, you can’t use\\nit. If a data scientist was trying to gro up similar customers, kn owing that statisti-\\ncal methods (called clustering ) can do this would be the first step.\\n\\x83 How to apply the techniques —Although a data scientist may know about many\\ntechniques, they also need to be able to understand the complexities of apply-\\ning them—not only how to write code to apply the methods, but also how to\\nconfigure them. If the data scientist wants to use a method such as k-means clus-\\ntering to group the customers, they would need to understand how to do k-means\\nDecision\\nscience\\nMath and\\nstats\\nProgramming\\nand databases\\nAnalytics\\nDomain\\nknowledge\\nMachine learning\\nFigure 1.1 The skills that combine to make data science and how they \\ncombine to make different roles\\nLicensed to Adriana Picoral <adrianaps@email.arizona.edu>'),\n",
              " Document(metadata={'source': 'pdfs/what_is_data_science.pdf', 'page': 2}, page_content='7What is data science?\\nclustering in a programming language such as R or Python. They would also\\nneed to understand how to adjust the parameters of the method, for example,\\nby choosing how many groups to create.\\n\\x83 How to choose which techniques to try —Because so many po ssible techniques can\\nbe used in data science, it’s important fo r the data scientist to be able to quickly\\nassess whether a technique would work well. In our customer grouping exam-\\nple, even after the data scientist focuses on clustering, they have to consider doz-\\nens of different methods and algorithms. Rather than trying each method, they\\nneed to be able to rule out methods quickly and focus on just a few.\\nThese sorts of skills are used constantly within a data science role. To consider a differ-\\nent example, suppose that you work at an  e-commerce company. Your business part-\\nner might be interested in wh at countries have the highest average order value. If you\\nhave the data available, this question is ea sy to answer. But rather  than simply present-\\ning this information and letting your custom er draw their own conclusions, you could\\ndig deeper. If you have one order from country A for $100, and a thousand orders\\nfrom country B that average $75, it is co rrect that country A has the higher average\\norder value. But would you be confident in sa ying that this means your business part-\\nner should definitely invest in advertisin g in country A to increase the number of\\norders? Probably not. You have only one da ta point for country A, and maybe it’s an\\noutlier. If country A had 500 orders instea d, you might use a statistical test to see\\nwhether the order value was significantly diff erent, meaning that if there really was no\\ndifference between A and B on this measur e, you’d be unlikely to see the difference\\nyou did. In this one paragraph-long exam ple, many different assessments were made\\non what approaches were se nsible, what should be considered, and what results were\\ndeemed to be unimportant.\\n1.1.2 Databases/programming\\nProgramming and databases  refer to the ability to pull data from company databases and\\nto write clean, efficient, maintainable co de. These skills are in many ways similar to\\nwhat a software developer has to know, except that data scientists have to write code\\nthat does open-ended analysis rather than  produces a predefin ed output. Each com-\\npany’s data stack is unique, so no one set of technical skills is required for a data scien-\\ntist. But broadly, you’ll need to know how to get data from a database and how to\\nclean, manipulate, summarize,  visualize, and share data.\\n In most data science jobs, R or Python is the main language. R is a programming\\nlanguage that has its roots in statistics, so it’s generally strongest for statistical analysis\\nand modeling, visualization, and generating reports with results. Python is a program-\\nming language that started as a genera l software development language and has\\nbecome extremely popular in data science. Python is known for being better than R at\\nworking with large datasets, doing machin e learning, and poweri ng real-time algo-\\nrithms (such as Amazon’s recommendation engines). But thanks to the work of many\\ncontributors, the two languages’  capabilities are now at near  parity. Data scientists are\\nLicensed to Adriana Picoral <adrianaps@email.arizona.edu>'),\n",
              " Document(metadata={'source': 'pdfs/what_is_data_science.pdf', 'page': 3}, page_content='8 CHAPTER  1 What is data science?\\nsuccessfully using R to make machine learning  models that are run millions of times a\\nweek, and they’re also making clean, pres entable statistical analyses in Python.\\n R and Python are the most popular lang uages for data science for a couple of\\nreasons:\\n\\x83 They’re free and open source, meaning that many people, not just one com-\\npany or one group, contribute code that  you can use. They have many packages\\nor libraries  (sets of code) for doing data colle ction, manipulation, visualization,\\nstatistical analysis, and machine learning.\\n\\x83 Importantly, because each lang uage has such a large foll owing, it’s easy for data\\nscientists to find help when they run into problems. Although some companies\\nstill use SAS, SPSS, STATA, MATLAB, or  other paid programs, many of them\\nare starting to move to R or Python instead.\\nAlthough most data science analysis is done  in R or Python, you’ll often need to work\\nwith a database to get the data. This is where the language SQL comes in. SQL is the\\nprogramming language that most databases us e to manipulate data within them or to\\nextract it. Consider a data scientist who wa nts to analyze the hundreds of millions of\\nrecords of customer orders in a company to forecast how orders per day will change\\nover time. First, they would likely write a SQL query to get the number of orders each\\nday. Then they would take those daily order counts and run a statistical forecast in R\\nor Python. For this reason, SQL is extremely popular in the data science community,\\nand it’s difficult to get too far without knowing it.\\n Another core skill is using version control —a method of keeping track of how code\\nchanges over time. Version control lets you st ore your files; revert them to a previous\\ntime; and see who changed what file, how, and when. This skill is extremely important\\nfor data science and software engineering because if someone accidentally changes a\\nfile that breaks your code, you want th e ability to revert or  see what changed.\\n  Git is by far the most commonly used sy stem for version control and is often used\\nin conjunction with GitHub, a web-based host ing service for Git. Git allows you to save\\n(commit ) your changes, as well as see the whole history of the project and how it\\nchanged with each commit. If two people ar e working on the same file separately, Git\\nmakes sure that no one’s work is ever ac cidentally deleted or overwritten. At many\\ncompanies, especially those with strong engineering teams, you’ll need to use Git if\\nyou want to share your code or put something into production.\\nCan you be a data scientist without programming?\\nIt’s possible to do a lot of data work using only Excel, Tableau, or other business intel-\\nligence tools that have graphical interfaces. Although you’re not writing code, these\\ntools claim to have much of the same functi onality as languages such as R or Python,\\nand many data scientist do use them sometimes. But can they be a complete data\\nscience toolkit? We say no. Practically, very few companies have a data science team\\nwhere you wouldn’t need to program. But ev en if that weren’t the case, programming\\nhas advantages over using these tools.\\nLicensed to Adriana Picoral <adrianaps@email.arizona.edu>'),\n",
              " Document(metadata={'source': 'pdfs/what_is_data_science.pdf', 'page': 4}, page_content='9What is data science?\\n1.1.3 Business understanding\\nAny sufficiently advanced technology  is indistinguishable from magic.\\nArthur C. Clarke\\nBusinesses have, to put it mildly, varying understanding of how data science works.\\nOften, management just wants something do ne and turns to its data science unicorns\\nto make that thing happen. A core skill in data science is knowing how to translate a\\nbusiness situation into a data  question, find the data answer, and finally deliver the\\nbusiness answer. A busi nessperson might ask, for exam ple, “Why are our customers\\nleaving?” But there’s no “why-are-custome rs-leaving” Python package that you can\\nimport—it’s up to you to deduce how to  answer that question with data.\\n Business understanding is where your data science ideals meet the practicalities of\\nthe real world. It’s not enough to want a specific piece of information without know-\\ning how the data is stored and updated at yo ur specific company. If your company is a\\nsubscription service, where does the data live? If someone changes their subscription,\\nwhat happens? Does that subscriber’s row ge t updated, or is another row added to the\\ntable? Do you need to work around any erro rs or inconsistencies in the data? If you\\ndon’t know the answers to these questions,  y o u  w o n ’ t  b e  a b l e  t o  g i v e  a n  a c c u r a t e\\nanswer to a basic question like “How many subscribers did we have on March 2, 2019?”\\n Business understanding also helps you kn ow what questions to ask. Being asked\\n“What should we do next?” by a stakeholder is a little like being asked “Why do we not\\nhave more money?” This type of question begs more questions. Developing an under-\\nstanding of the core business (as well as th e personalities involved) can help you parse\\nthe situation better. You might follow up with  “Which product line are you looking for\\nguidance regarding?” or “Would you like to  see more participation from a certain sec-\\ntor of our audience?”\\nThe first advantage of programming is repr oducibility. When you write code instead of\\nusing point-and-click software, you’re able to rerun it whenever your data changes,\\nwhether that’s every day or in six months. This advantage also ties into version con-\\ntrol: instead of renaming your file every time your code changes, you can keep one\\nfile but see its entire history.\\nThe second advantage is  flexibility. If Table au doesn’t have a type of graph available,\\nfor example, you won’t be able to create it. But with programming, you can write your\\nown code to make something that the creators and maintainers of a tool never\\nthought of.\\nThe third and final advantage of open source languages such as Python and R is com-\\nmunity contribution. Thousands of people create packages , and publish them openly\\non GitHub and/or CRAN (for R) and pip (for Python). You can download this code and\\nuse it for your own problems. You’re not reliant on one company or group of people\\nto add features.\\nLicensed to Adriana Picoral <adrianaps@email.arizona.edu>'),\n",
              " Document(metadata={'source': 'pdfs/what_is_data_science.pdf', 'page': 5}, page_content='10 CHAPTER  1 What is data science?\\n Another part of business understanding is  developing general business skills, such as\\nbeing able to tailor your presentations and reports to different audiences. Sometimes,\\nyou’ll be discussing a better methodology with  a room full of statistics PhDs, and some-\\ntimes, you’ll be in front of a vice president who hasn’t taken a math class in 20 years. You\\nneed to inform your audience without either talking down or overcomplicating.\\n Finally, as you become more senior, part of your job is to identify where the busi-\\nness could benefit from data science. If you’ ve wanted to build a prediction system for\\nyour company but have never had manageme nt support, becoming  part of the man-\\nagement team can help solve th at problem. A senior data scientist will be on the look-\\nout for places to implement machine lear ning, as they know its limitations and\\ncapabilities, as well as which kinds of  tasks would benefit from automation.\\n1.2 Different types of data science jobs\\nYou can mix and match the three core skills of data science (covered in section 1.1)\\ninto several jobs, all of which have some justification for having the title data scientist.\\nFrom our perspective, these skills get mixe d together in three main ways: analytics,\\nmachine learning, and decision  science. Each of those ar eas serves a different pur-\\npose for the company and fundamen tally delivers a different thing.\\nWill data science disappear?\\nUnderlying the question abou t whether data science will be around in a decade or two\\nare two main concerns: that the job will become automate d and that data science is\\noverhyped and the job-ma rket bubble will pop.\\nIt’s true that certain parts of the data science pipeline can be automated. Automated\\nMachine Learning (AutoML) can compare the performance of different models and\\nperform certain parts of data preparation (such as scaling variables). But these tasks\\nare just a small part of the data science pr ocess. You’ll often need to create the data\\nyourself, for example; it’s very rare to have  perfectly clean data waiting for you. Also,\\ncreating the data usually involves talking with other people, such as user experience\\nresearchers or engineers, who will conduc t the survey or log the user actions that can\\ndrive your analysis.\\nRegarding the possibility of a pop in a job-ma rket bubble, a good comparison is soft-\\nware engineering in the 1980 s. As computers grew cheaper , faster, an d more com-\\nmon, there were concerns that soon a comp uter could do everyt hing and that there\\nwould be no need for programmers. But the opposite thing happened, and now there\\nare more than 1.2 millio n software engineers in  the United States ( http:/ /mng.bz/\\nMOPo ). Although titles such as webmaster did disappear, more people than ever are\\nworking on website development, maintenance, and improvement. \\nWe believe that there will be  more specializatio n within data science, which may lead\\nto the disappearance of the general title da ta scientist, but many companies are still\\nin the early stages of learning how to leve rage data science and there’s plenty of work\\nleft to do.\\nLicensed to Adriana Picoral <adrianaps@email.arizona.edu>'),\n",
              " Document(metadata={'source': 'pdfs/what_is_data_science.pdf', 'page': 6}, page_content='11Different types of data science jobs\\n When looking for data science jobs, you should pay less attention to the job titles\\nand more to the job descriptions and what yo u’re asked in the interviews. Look at the\\nbackgrounds of people in data science roles, such as what previous jobs they held and\\nwhat their degrees are. You may find that people who work in similar-sounding jobs\\nhave totally different titles or that people  w h o  h a v e  t h e  s a m e  d a t a  s c i e n t i s t  t i t l e  d o\\ntotally different things. As we talk in this  book about different types of data science\\njobs, remember that the actual ti tles used at companies may vary.\\n1.2.1 Analytics\\nAn analyst  takes data and puts it in front of th e right people. After a company sets its\\nyearly goals, you might put those goals in a dashboard so that management can track\\nprogress every week. You coul d also build in features that allow managers to easily\\nbreak down the numbers by country or produc t type. This work involves a lot of data\\ncleaning and preparation but generally less work to interpret the data. Although you\\nshould be able to spot and fix data qu ality issues, the primary person who makes\\ndecisions with this data is th e business partner. Thus, the job of an analyst is to take\\ndata from within the company, format and ar range it effectively, and deliver that data\\nto others.\\n Because the analyst’s role doesn’t involve a lot of statistics and machine learning,\\nsome people and companies would consider th is role to be outside the field of data\\nscience. But much of the work, such as de vising meaningful visualizations and decid-\\ning on particular data transformations, requir es the same skills used in the other types\\nof data science roles. An analyst might be given a task such as “Create an automated\\ndashboard that shows how our number of subscribers is ch anging over time and lets\\nus filter the data to just subscribers of sp ecific products or in specific geographical\\nregions.” The analyst would have to find th e appropriate data within the company, fig-\\nure out how to transform the data appropriat ely (such as by changing it from daily to\\nweekly new subscriptions), and then create  a meaningful set of dashboards that are\\nvisually compelling and automaticall y update each day without errors.\\n Short rule: an analyst creates  dashboards and reports that deliver data.\\n1.2.2 Machine learning\\nA machine learning engineer  develops machine learning mo dels and puts them into pro-\\nduction, where they run continuously. They  may optimize the ranking algorithm for\\nthe search results of an e-commerce site, create a recommendation system, or monitor\\na model in production to make sure that it s performance hasn’t de graded since it was\\ndeployed. A machine learning engineer spends less time on things like creating visual-\\nizations that will convince people of something and more time doing the program-\\nming work of data science.\\n A big difference between this role and othe r types of data science positions is that\\nthe work output is primarily for machin e consumption. You might create machine\\nlearning models that get turned into appl ication programming interfaces (APIs) for\\nLicensed to Adriana Picoral <adrianaps@email.arizona.edu>'),\n",
              " Document(metadata={'source': 'pdfs/what_is_data_science.pdf', 'page': 7}, page_content='12 CHAPTER  1 What is data science?\\nother machines, for example. In many ways, you’ll be closer to a software developer\\nthan to other data science ro les. Although it’s good for any data scientist to follow\\nbest coding practices, as a machine lear ning engineer, you must do so. Your code\\nmust be performant, tested, and written so that other people will be able to work\\nwith it. For this reason, many machine learning engineers come from a computer\\nscience background.\\n In a machine learning engineer role, a person may be asked to create a machine\\nlearning model that can—in real time—predi ct the probability that a customer on the\\nwebsite will actually finish their order. The machine learning engineer would have to\\nfind historical data in the company, trai n a machine learning model on it, turn that\\nmodel into an API, and then deploy the AP I so that the website can run the model. If\\nthat model stops working for some reason , the machine learning engineer will be\\ncalled to fix it.\\n Short rule: a machine learning engineer creates models that get run continuously.\\n1.2.3 Decision science\\nA decision scientist  turns a company’s raw data into information that helps the company\\nmake decisions. This work relies on having deep understanding of different mathe-\\nmatical and statistical methods and familiar ity with business decision-making. Further-\\nmore, decision scientists have to be able to make compelling visualizations and tables\\nso that the nontechnical people they talk to  will understand their analysis. Although a\\ndecision scientist does plenty of progra mming, their work generally gets run only\\nonce to make a particular analysis, so they can get away with having code that’s ineffi-\\ncient or difficult to maintain.\\n A  d e c i s i o n  s c i e n t i s t  m u s t  u n d e r s t a n d  t he needs of the other people within the\\ncompany and figure out how to generate co nstructive information. A marketing direc-\\ntor, for example, might ask a decision scientist to help them decide which types of\\nproducts should be highlighted in the comp any’s holiday gift guid e. The decision sci-\\nentist might investigate what products have sold well without being featured in the gift\\nguide, talk to the user research team abou t conducting a survey, and use principles of\\nbehavioral science to do an analysis to co me up with the optimal items to suggest. The\\nresult is likely to be a PowerPoint presentation or report to be shared with product\\nmanagers, vice presidents, and other businesspeople.\\n A decision scientist often uses their knowledge of statistics to help the company\\nmake decisions under uncertainty. A decisi on scientist could be  responsible for run-\\nning their company’s experimentation analyt ics system, for example. Many companies\\nrun online experiments, or A/ B tests, to measur e whether a change is effective. This\\nchange could be as simple as adding a ne w button or as complicated as changing the\\nranking system of search results or complete ly redesigning a page. During an A/B test,\\nvisitors are randomly assigned to one of tw o or more conditions, such as half to the\\nold version of the home page, which is the control , and half to the new version, which\\nis the treatment . Then visitors’ actions after they  enter the experiment are compared\\nLicensed to Adriana Picoral <adrianaps@email.arizona.edu>'),\n",
              " Document(metadata={'source': 'pdfs/what_is_data_science.pdf', 'page': 8}, page_content='13Different types of data science jobs\\nto see whether those in the treatment have  a  h i g h e r  r a t e  o f  p e r f o r m i n g  d e s i r a b l e\\nactions, such as buying products.\\n Because of randomness, it’s rare for the metrics in the control and treatment to be\\nexactly the same. Suppose that you flipped two coins, and that one turned up heads\\n52 times out of 100 and one 49 times out of 100. Would you conclude that the first\\ncoin is more likely to turn up heads? Of course not! But a busi ness partner might look\\nat an experiment, see that th e conversion rate is 5.4 pe rcent in the control and 5.6\\npercent in the treatment, and declare the tr eatment to be a success. The decision sci-\\nentist is there to help interpret the data, enforce best practices for designing experi-\\nments, and more.\\n Short rule: a decision scientist creates analyses that produce recommendations .\\n1.2.4 Related jobs\\nAlthough the three areas disc ussed in the preceding sect ions are the main types of\\ndata science positions, you ma y see a few other distinct roles that fall outside those cat-\\negories. We list those jobs here, because it’s  good to understand the positions that are\\nout there and because you may need to colla borate with colleagues in these positions.\\nThat said, if you’re interested in one of th ese roles, the material in this book may be\\nless relevant to you.\\nBUSINESS  INTELLIGENCE  ANALYST\\nA business intelligence analyst  does work similar to that of an analyst, but they generally\\nuse less statistical and programming expertis e. Their tool of choice may be Excel\\ninstead of Python, and they may not ever ma ke statistical models . Although their job\\nfunction is similar to that of an analyst, they create less-sophisticated output because\\nof the limitations of th eir tools and techniques.\\n If you want to do machine learning or programming, or to apply statistical meth-\\nods, a business intelligence analyst position could be a very frustrating role, because it\\nwon’t help you gain new skills. Also, these jobs usually pay less than data science jobs\\nand are considered to be less prestigious. But a business intelligence analyst job can\\nbe a good entry point to becoming a data scientist, especially if you haven’t worked\\nwith data in a business setting before. If you want to start as a business intelligence\\nanalyst and grow into becoming  a data scientist, look for positions in which you can\\nlearn some skills you may not have, su ch as programming in R or Python.\\nDATA  ENGINEER\\nA data engineer  f o c u s e s  o n  k e e p i n g  d a t a  m a i n t a i ned in databases and ensuring that\\npeople can get the data they need. They don’t run reports, make analyses, or develop\\nmodels; instead, they keep the data neatly  stored and formatted in well-structured\\ndatabases so that other people can do th ose things. A data engineer may be tasked\\nwith maintaining all the customer records in a large-scale cloud database and adding\\nnew tables to that database as requested.\\n Data engineers are pretty different from data scientists, and they’re even more rare\\nand in demand. A data engineer may help build the data backend components of a\\nLicensed to Adriana Picoral <adrianaps@email.arizona.edu>'),\n",
              " Document(metadata={'source': 'pdfs/what_is_data_science.pdf', 'page': 9}, page_content='14 CHAPTER 1 What is data science?\\ncompany’s internal experimentation system and update the data processing flow when\\nthe jobs start taking too long. Other data  engineers develop and monitor batch and\\nstreaming environments, managing data from collection to processing to data storage.\\n If you’re interested in data engineer ing, you’ll need strong computer science\\nskills; many data engineers are former software engineers.\\nRESEARCH SCIENTIST\\nA research scientist develops and implements new tools, algorithms, and methodologies,\\noften to be used by other data scientists within the company. These types of positions\\nalmost always require PhDs, us ually in computer science, statistics, quantitative social\\nscience, or a related field. Research scientists may spend weeks researching and trying\\nout methods to increase the power of onli ne experiments, getting 1% more accuracy\\non image recognition in self-driving cars, or building a new deep  learning algorithm.\\nThey may even spend time writing research pa pers that may rarely be used within the\\ncompany but that help raise the prestige of the company and (ideally) advance the\\nfield. Because these positions require very  s p e c i f i c  b a c k g r o u n d s ,  w e  d o n ’ t  f o c u s  o n\\nthem in this book.\\nLicensed to Adriana Picoral <adrianaps@email.arizona.edu>')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunkins"
      ],
      "metadata": {
        "id": "KGYUaj3eNykP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "bXHGpiZ5NVHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
        "text_chunks = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "_TCZawOWNez8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV2CrWAINnE1",
        "outputId": "02b9597b-73b4-410d-d861-24971f801e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbwqGwRYNnCU",
        "outputId": "c49c6b74-2620-405d-dcef-0f063ed74a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'pdfs/what_is_data_science.pdf', 'page': 0}, page_content='historical data of locations where online orders are shipped to understand where cus-\\ntomer demand is. They may also combine that customer location data with demo-\\ngraphic and income information for those loca lities from census records. With these\\ndatasets, they could find the optimal plac e for the new store and create a Microsoft\\nPowerPoint presentation to  p r e s e n t  t h e i r  r e c o m m e n d a t i o n  t o  t h e  c o m p a n y ’ s  v i c e\\npresident of retail operations.')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings"
      ],
      "metadata": {
        "id": "tIY40r0rN00u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "UIAnc8_WNsp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gK-13RwahzI",
        "outputId": "a8b164f8-4a4a-409f-864d-3370fb208beb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.9.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "sentences = [\n",
        "    \"That is a happy person\",\n",
        "    \"That is a happy dog\",\n",
        "    \"That is a very happy person\",\n",
        "    \"Today is a sunny day\"\n",
        "]\n",
        "embeddings = model.encode(sentences)\n",
        "\n",
        "similarities = model.similarity(embeddings, embeddings)\n",
        "print(similarities.shape)\n",
        "# [4, 4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "LHrv8g49Xgw1",
        "outputId": "8226c97e-7fa5-4070-a71d-a1088f966744",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'cached_download' from 'huggingface_hub' (/usr/local/lib/python3.10/dist-packages/huggingface_hub/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-ee6dc5bc7978>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentence-transformers/all-MiniLM-L6-v2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m sentences = [\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"2.2.2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0m__MODEL_HUB_ORGANIZATION__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sentence-transformers'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentencesDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParallelSentencesDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mLoggingHandler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoggingHandler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mSentenceTransformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mDenoisingAutoEncoderDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDenoisingAutoEncoderDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mNoDuplicatesDataLoader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNoDuplicatesDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mParallelSentencesDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallelSentencesDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mSentencesDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentencesDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mSentenceLabelDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceLabelDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/datasets/ParallelSentencesDataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputExample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHfApi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHfFolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRepository\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_hub_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'cached_download' from 'huggingface_hub' (/usr/local/lib/python3.10/dist-packages/huggingface_hub/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "fJTFv3GaOAnu",
        "outputId": "aa11454d-25a5-44d0-a52f-940be92a9dde",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/huggingface.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0m__MODEL_HUB_ORGANIZATION__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sentence-transformers'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentencesDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParallelSentencesDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mLoggingHandler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoggingHandler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mNoDuplicatesDataLoader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNoDuplicatesDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mParallelSentencesDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallelSentencesDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mSentencesDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentencesDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/datasets/ParallelSentencesDataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputExample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHfApi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHfFolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRepository\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_hub_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'cached_download' from 'huggingface_hub' (/usr/local/lib/python3.10/dist-packages/huggingface_hub/__init__.py)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-83794808db26>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHuggingFaceEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sentence-transformers/all-MiniLM-L6-v2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                         \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 obj.__init__ = functools.wraps(obj.__init__)(  # type: ignore[misc]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/huggingface.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0;34m\"Could not import sentence_transformers python package. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;34m\"Please install it with `pip install sentence-transformers`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_result = embeddings.embed_query(\"Hello World\")"
      ],
      "metadata": {
        "id": "g9U0vZ1GOOhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Veg_iJqKOWo0",
        "outputId": "5bc2ee44-9ca1-4348-ffd6-05dc873c27b6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.03447723016142845,\n",
              " 0.03102324716746807,\n",
              " 0.006734959781169891,\n",
              " 0.0261090025305748,\n",
              " -0.03936202824115753,\n",
              " -0.16030246019363403,\n",
              " 0.06692398339509964,\n",
              " -0.0064414688386023045,\n",
              " -0.047450464218854904,\n",
              " 0.014758829958736897,\n",
              " 0.07087527215480804,\n",
              " 0.05552761256694794,\n",
              " 0.01919332519173622,\n",
              " -0.026251330971717834,\n",
              " -0.010109531693160534,\n",
              " -0.02694046124815941,\n",
              " 0.022307436913251877,\n",
              " -0.022226616740226746,\n",
              " -0.1496926099061966,\n",
              " -0.017493003979325294,\n",
              " 0.007676253095269203,\n",
              " 0.05435232073068619,\n",
              " 0.0032544638961553574,\n",
              " 0.03172587975859642,\n",
              " -0.08462142199277878,\n",
              " -0.02940596640110016,\n",
              " 0.05159560963511467,\n",
              " 0.04812396690249443,\n",
              " -0.003314846893772483,\n",
              " -0.05827917903661728,\n",
              " 0.04196927696466446,\n",
              " 0.022210661321878433,\n",
              " 0.128188818693161,\n",
              " -0.022338954731822014,\n",
              " -0.01165623590350151,\n",
              " 0.06292833387851715,\n",
              " -0.03287631273269653,\n",
              " -0.09122607111930847,\n",
              " -0.03117535635828972,\n",
              " 0.052699532359838486,\n",
              " 0.04703482240438461,\n",
              " -0.08420310169458389,\n",
              " -0.030056189745664597,\n",
              " -0.020744824782013893,\n",
              " 0.009517835453152657,\n",
              " -0.003721772227436304,\n",
              " 0.007343326695263386,\n",
              " 0.039324309676885605,\n",
              " 0.09327401965856552,\n",
              " -0.003788610687479377,\n",
              " -0.052742067724466324,\n",
              " -0.0580582320690155,\n",
              " -0.006864381488412619,\n",
              " 0.0052832672372460365,\n",
              " 0.082893006503582,\n",
              " 0.01936277002096176,\n",
              " 0.00628449022769928,\n",
              " -0.010330758057534695,\n",
              " 0.00903238169848919,\n",
              " -0.03768371418118477,\n",
              " -0.045206114649772644,\n",
              " 0.024016307666897774,\n",
              " -0.006944143678992987,\n",
              " 0.01349161472171545,\n",
              " 0.10005496442317963,\n",
              " -0.0716838464140892,\n",
              " -0.021695079281926155,\n",
              " 0.03161846846342087,\n",
              " -0.051634639501571655,\n",
              " -0.08224771171808243,\n",
              " -0.06569331139326096,\n",
              " -0.009895361959934235,\n",
              " 0.0058164168149232864,\n",
              " 0.07355455309152603,\n",
              " -0.03405029699206352,\n",
              " 0.024886101484298706,\n",
              " 0.014488073997199535,\n",
              " 0.02645738422870636,\n",
              " 0.00965672917664051,\n",
              " 0.030217260122299194,\n",
              " 0.05280398577451706,\n",
              " -0.07535990327596664,\n",
              " 0.009897175244987011,\n",
              " 0.02983679622411728,\n",
              " 0.017555631697177887,\n",
              " 0.023091984912753105,\n",
              " 0.0019338561687618494,\n",
              " 0.0014001855161041021,\n",
              " -0.04717599228024483,\n",
              " -0.011194337159395218,\n",
              " -0.11420140415430069,\n",
              " -0.019811954349279404,\n",
              " 0.040266215801239014,\n",
              " 0.0021929622162133455,\n",
              " -0.07979221642017365,\n",
              " -0.02538228966295719,\n",
              " 0.09448293596506119,\n",
              " -0.02898111194372177,\n",
              " -0.14500252902507782,\n",
              " 0.23097746074199677,\n",
              " 0.027731146663427353,\n",
              " 0.032111503183841705,\n",
              " 0.03106497786939144,\n",
              " 0.04283283278346062,\n",
              " 0.06423775851726532,\n",
              " 0.03216319531202316,\n",
              " -0.00487672770395875,\n",
              " 0.05569944158196449,\n",
              " -0.03753243759274483,\n",
              " -0.021505527198314667,\n",
              " -0.02834269590675831,\n",
              " -0.02884691022336483,\n",
              " 0.038353100419044495,\n",
              " -0.017468662932515144,\n",
              " 0.05248526856303215,\n",
              " -0.07487602531909943,\n",
              " -0.03125971555709839,\n",
              " 0.02184155210852623,\n",
              " -0.03989572450518608,\n",
              " -0.008587054908275604,\n",
              " 0.026956621557474136,\n",
              " -0.04849553480744362,\n",
              " 0.011469872668385506,\n",
              " 0.02961817942559719,\n",
              " -0.02057218924164772,\n",
              " 0.013103866018354893,\n",
              " 0.028833502903580666,\n",
              " -3.1942001868481724e-33,\n",
              " 0.06478209793567657,\n",
              " -0.018130190670490265,\n",
              " 0.05178993195295334,\n",
              " 0.12198275327682495,\n",
              " 0.028780195862054825,\n",
              " 0.008721966296434402,\n",
              " -0.07052118331193924,\n",
              " -0.016907261684536934,\n",
              " 0.04073968529701233,\n",
              " 0.0421161912381649,\n",
              " 0.025447169318795204,\n",
              " 0.035746268928050995,\n",
              " -0.04914474859833717,\n",
              " 0.002129054395481944,\n",
              " -0.015546581707894802,\n",
              " 0.05073055624961853,\n",
              " -0.048185352236032486,\n",
              " 0.03588063642382622,\n",
              " -0.004067042376846075,\n",
              " 0.10172469168901443,\n",
              " -0.05597005411982536,\n",
              " -0.010681052692234516,\n",
              " 0.011235786601901054,\n",
              " 0.09068653732538223,\n",
              " 0.0042344750836491585,\n",
              " 0.03513867035508156,\n",
              " -0.009702837094664574,\n",
              " -0.09386517852544785,\n",
              " 0.0928555503487587,\n",
              " 0.00800492987036705,\n",
              " -0.00770539278164506,\n",
              " -0.052086714655160904,\n",
              " -0.01258798222988844,\n",
              " 0.0032669547945261,\n",
              " 0.006013563368469477,\n",
              " 0.007581565994769335,\n",
              " 0.010517148301005363,\n",
              " -0.08634557574987411,\n",
              " -0.06987878680229187,\n",
              " -0.0025338572449982166,\n",
              " -0.09097656607627869,\n",
              " 0.04688732326030731,\n",
              " 0.05207647755742073,\n",
              " 0.007193842902779579,\n",
              " 0.010903630405664444,\n",
              " -0.005229530856013298,\n",
              " 0.013937319628894329,\n",
              " 0.02196837030351162,\n",
              " 0.03420859947800636,\n",
              " 0.0602247379720211,\n",
              " 0.00011663648911053315,\n",
              " 0.014731980860233307,\n",
              " -0.07008926570415497,\n",
              " 0.028499029576778412,\n",
              " -0.027601728215813637,\n",
              " 0.010768433101475239,\n",
              " 0.03483092039823532,\n",
              " -0.022487852722406387,\n",
              " 0.009769024327397346,\n",
              " 0.07722782343626022,\n",
              " 0.021588405594229698,\n",
              " 0.11495617032051086,\n",
              " -0.06800113618373871,\n",
              " 0.023761006072163582,\n",
              " -0.01598392426967621,\n",
              " -0.01782693900167942,\n",
              " 0.06439489126205444,\n",
              " 0.03202572837471962,\n",
              " 0.05027027055621147,\n",
              " -0.005913708824664354,\n",
              " -0.033708006143569946,\n",
              " 0.01784025877714157,\n",
              " 0.016573328524827957,\n",
              " 0.06329655647277832,\n",
              " 0.03467718884348869,\n",
              " 0.04647346958518028,\n",
              " 0.09790616482496262,\n",
              " -0.006635494530200958,\n",
              " 0.02520707994699478,\n",
              " -0.07798830419778824,\n",
              " 0.016926458105444908,\n",
              " -0.0009458208223804832,\n",
              " 0.022471945732831955,\n",
              " -0.03825317323207855,\n",
              " 0.09570476412773132,\n",
              " -0.005350801628082991,\n",
              " 0.010469069704413414,\n",
              " -0.11524056643247604,\n",
              " -0.013262507505714893,\n",
              " -0.010709423571825027,\n",
              " -0.0831172913312912,\n",
              " 0.07327356189489365,\n",
              " 0.049392219632864,\n",
              " -0.008994399569928646,\n",
              " -0.09584557265043259,\n",
              " 3.366149296434549e-33,\n",
              " 0.12493184208869934,\n",
              " 0.019349751994013786,\n",
              " -0.058225758373737335,\n",
              " -0.035988226532936096,\n",
              " -0.05074675381183624,\n",
              " -0.045662377029657364,\n",
              " -0.08260340243577957,\n",
              " 0.14819477498531342,\n",
              " -0.08842118084430695,\n",
              " 0.06027441471815109,\n",
              " 0.05103014037013054,\n",
              " 0.010303163900971413,\n",
              " 0.14121417701244354,\n",
              " 0.030813826248049736,\n",
              " 0.061033111065626144,\n",
              " -0.052851270884275436,\n",
              " 0.13664887845516205,\n",
              " 0.0091899074614048,\n",
              " -0.017325228080153465,\n",
              " -0.012848632410168648,\n",
              " -0.007995309308171272,\n",
              " -0.05098005756735802,\n",
              " -0.05235065147280693,\n",
              " 0.0075930156745016575,\n",
              " -0.015166294761002064,\n",
              " 0.016960354521870613,\n",
              " 0.0212705135345459,\n",
              " 0.02055802382528782,\n",
              " -0.12002810090780258,\n",
              " 0.014461856335401535,\n",
              " 0.026759885251522064,\n",
              " 0.02533065713942051,\n",
              " -0.04275466129183769,\n",
              " 0.006768449675291777,\n",
              " -0.014458571560680866,\n",
              " 0.045261986553668976,\n",
              " -0.09147653728723526,\n",
              " -0.019439108669757843,\n",
              " -0.01783355139195919,\n",
              " -0.05491022765636444,\n",
              " -0.05264104902744293,\n",
              " -0.010459104552865028,\n",
              " -0.05201607570052147,\n",
              " 0.020892007276415825,\n",
              " -0.07997032254934311,\n",
              " -0.012111310847103596,\n",
              " -0.05773141235113144,\n",
              " 0.02317827381193638,\n",
              " -0.008031700737774372,\n",
              " -0.025989260524511337,\n",
              " -0.07995673269033432,\n",
              " -0.020728835836052895,\n",
              " 0.04881769046187401,\n",
              " -0.020389148965477943,\n",
              " -0.04917658865451813,\n",
              " 0.014159608632326126,\n",
              " -0.06362206488847733,\n",
              " -0.007807428017258644,\n",
              " 0.016431519761681557,\n",
              " -0.025682495906949043,\n",
              " 0.013381104916334152,\n",
              " 0.02624877355992794,\n",
              " 0.009978440590202808,\n",
              " 0.06322886049747467,\n",
              " 0.0026721598114818335,\n",
              " -0.006582802627235651,\n",
              " 0.0166319590061903,\n",
              " 0.032366473227739334,\n",
              " 0.03794248774647713,\n",
              " -0.03637608885765076,\n",
              " -0.006910903379321098,\n",
              " 0.00015972662367857993,\n",
              " -0.0016335482941940427,\n",
              " -0.027278197929263115,\n",
              " -0.02803807333111763,\n",
              " 0.049681492149829865,\n",
              " -0.02886720560491085,\n",
              " -0.0024180845357477665,\n",
              " 0.014774910174310207,\n",
              " 0.009764612652361393,\n",
              " 0.00579760130494833,\n",
              " 0.013486153446137905,\n",
              " 0.005567883141338825,\n",
              " 0.03722711279988289,\n",
              " 0.007232483476400375,\n",
              " 0.04015623405575752,\n",
              " 0.0815032348036766,\n",
              " 0.07199164479970932,\n",
              " -0.013056199066340923,\n",
              " -0.04288206249475479,\n",
              " -0.011011229828000069,\n",
              " 0.00489779794588685,\n",
              " -0.009229722432792187,\n",
              " 0.03519152104854584,\n",
              " -0.051035065203905106,\n",
              " -1.571437557856825e-08,\n",
              " -0.08862435817718506,\n",
              " 0.023909317329525948,\n",
              " -0.016238726675510406,\n",
              " 0.031700462102890015,\n",
              " 0.027284229174256325,\n",
              " 0.052468813955783844,\n",
              " -0.047070957720279694,\n",
              " -0.05884746089577675,\n",
              " -0.06320822983980179,\n",
              " 0.04088856279850006,\n",
              " 0.04982796311378479,\n",
              " 0.10655166953802109,\n",
              " -0.07450232654809952,\n",
              " -0.012495473958551884,\n",
              " 0.01837066002190113,\n",
              " 0.039474114775657654,\n",
              " -0.02479788102209568,\n",
              " 0.014516300521790981,\n",
              " -0.03706921637058258,\n",
              " 0.02001575194299221,\n",
              " -4.8584795877104625e-05,\n",
              " 0.00986657477915287,\n",
              " 0.024838771671056747,\n",
              " -0.05245811119675636,\n",
              " 0.02931424230337143,\n",
              " -0.08719190210103989,\n",
              " -0.01449974812567234,\n",
              " 0.026019049808382988,\n",
              " -0.018746353685855865,\n",
              " -0.07620511949062347,\n",
              " 0.03504332900047302,\n",
              " 0.10363949835300446,\n",
              " -0.0280505008995533,\n",
              " 0.012718193233013153,\n",
              " -0.07632550597190857,\n",
              " -0.01865236647427082,\n",
              " 0.024976734071969986,\n",
              " 0.0814453661441803,\n",
              " 0.06875886023044586,\n",
              " -0.06405668705701828,\n",
              " -0.08389386534690857,\n",
              " 0.0613623782992363,\n",
              " -0.03354552015662193,\n",
              " -0.10615336894989014,\n",
              " -0.04008055105805397,\n",
              " 0.03253018110990524,\n",
              " 0.07662486284971237,\n",
              " -0.07301623374223709,\n",
              " 0.0003375916858203709,\n",
              " -0.04087158665060997,\n",
              " -0.07578849047422409,\n",
              " 0.027527645230293274,\n",
              " 0.0746254250407219,\n",
              " 0.01771722547709942,\n",
              " 0.09121845662593842,\n",
              " 0.11022021621465683,\n",
              " 0.0005698355962522328,\n",
              " 0.051463380455970764,\n",
              " -0.014551321975886822,\n",
              " 0.03323201462626457,\n",
              " 0.023792298510670662,\n",
              " -0.022889873012900352,\n",
              " 0.03893754258751869,\n",
              " 0.030206849798560143]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Length\", len(query_result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4S3r-RGOYEk",
        "outputId": "3200b30d-bcb9-4373-93bd-8ea12394d085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length 384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing the Pinecone"
      ],
      "metadata": {
        "id": "kjDDGZ1IOd10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "gHHNhKtaOinp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY', '6ee7dc8a-43fb-4480-8774-f1d02577386d')\n",
        "PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV', 'gcp-starter')"
      ],
      "metadata": {
        "id": "jsSRlRM3ObeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "# initialize pinecone\n",
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
        "    environment=PINECONE_API_ENV  # next to api key in console\n",
        ")\n",
        "index_name = \"test\" # put in the name of your pinecone index here\n"
      ],
      "metadata": {
        "id": "tLBDqUA5PDq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Pinecone"
      ],
      "metadata": {
        "id": "jS18M0OgPUf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch = Pinecone.from_texts([t.page_content for t in text_chunks], embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "xA40p1jMPMx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## If you already have an index, you can load it like this"
      ],
      "metadata": {
        "id": "aMMqIPGLP8hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch = Pinecone.from_existing_index(index_name, embeddings)\n",
        "docsearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abeq0PEmPfiu",
        "outputId": "723acd67-2212-4330-ac6b-37243cd4e774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.pinecone.Pinecone at 0x7f18570e3910>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Similarity Search"
      ],
      "metadata": {
        "id": "6rf0vT0TQHD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is yolo?\""
      ],
      "metadata": {
        "id": "2QPqDP4uPfgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = docsearch.similarity_search(query, k=3)"
      ],
      "metadata": {
        "id": "SdTGw7HsPfd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhG7x4O0QRYX",
        "outputId": "6df52aa8-af40-47b2-fb2a-1478edf6a01e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='image each time leading to less false positives (has contextual information for detection) YOLO algorithm'),\n",
              " Document(page_content='CS391R: Robot Learning (Fall 2021)20Discussion of Results❖Pro: YOLO is a lot faster than the other algorithms for image detection❖Pro: YOLO’s use of global information rather than only local information allows it to understand contextual information when doing object detection➢Does better in domains such as artwork due to this❖Con: YOLO lagged behind the SOTA models in object detection➢This is attributed to making many localization errors and unable to detect small object'),\n",
              " Document(page_content='CS391R: Robot Learning (Fall 2021)2Problem Addressed: Object Detection❖Object detection is the problem of both locating ANDclassifying objects ❖Goal of YOLO algorithm is to do object detection both fast ANDwith high accuracy\\n“Deep Learning for Vision Systems” (Elgendy)Object Detection vs Classification')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWp8rA1-QSWd",
        "outputId": "fb4293f6-d0c5-4395-94ab-d8a13863a868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqnA7aNTQqx2",
        "outputId": "1917ad4c-8996-4a90-f0d8-fed2309cfddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "YJ5-RaMYQin9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "gaik-DpJQkmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "OefT4CPyQcVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI()"
      ],
      "metadata": {
        "id": "MCgk1uIUQT1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "lhFq_WGjQoCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
      ],
      "metadata": {
        "id": "zxUZ3U2SQ17s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is yolo?\""
      ],
      "metadata": {
        "id": "y9FMCDRyQ5BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(qa.run(query))"
      ],
      "metadata": {
        "id": "pNsMZ2r-Q8Rs",
        "outputId": "aa57d8c6-4a8c-4f83-cd29-07124e98c9ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " YOLO is an algorithm used for object detection in images. It is known for its speed and ability to understand contextual information, but it may lag behind other state-of-the-art models in accuracy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vpdZno-uQ9Se"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}